# configs/models_api.yaml
use_api: true

model_1:
  model_name: "google/gemma-2-2b-it"
  max_new_tokens: 64
  temperature: 0.7

model_2:
  model_name: "google/gemma-2-9b-it"
  max_new_tokens: 64
  temperature: 0.7

model_3:
  model_name: "google/gemma-3-12b-it"
  max_new_tokens: 64
  temperature: 0.7

model_4:
  model_name: "google/gemma-3-27b-it"
  max_new_tokens: 64
  temperature: 0.7

model_5:
  model_name: "mistralai/Mistral-7B-Instruct-v0.3"
  max_new_tokens: 64
  temperature: 0.7

model_6:
  model_name: "mistralai/Mixtral-8x7B-Instruct-v0.1"
  max_new_tokens: 64
  temperature: 0.7

model_7:
  model_name: "mistralai/Mistral-Small-3.1-24B-Instruct-2503"
  max_new_tokens: 64
  temperature: 0.7

model_8:
  model_name: "mistralai/Mixtral-8x22B-Instruct-v0.1"
  max_new_tokens: 64
  temperature: 0.7

model_9:
  model_name: "mistralai/Mistral-Nemo-Base-2407"
  max_new_tokens: 64
  temperature: 0.7

model_10:
  model_name: "meta-llama/Llama-3.2-1B-Instruct"
  max_new_tokens: 64
  temperature: 0.7

model_11:
  model_name: "meta-llama/Llama-3.2-3B-Instruct"
  max_new_tokens: 64
  temperature: 0.7

model_12:
  model_name: "meta-llama/Llama-3.1-8B-Instruct"
  max_new_tokens: 64
  temperature: 0.7

model_13:
  model_name: "meta-llama/Llama-3.3-70B-Instruct"
  max_new_tokens: 64
  temperature: 0.7

model_14:
  model_name: "meta-llama/Llama-3.1-405B-Instruct"
  max_new_tokens: 64
  temperature: 0.7

model_15:
  model_name: "Qwen/Qwen3-1.7B"
  max_new_tokens: 64
  temperature: 0.7

model_16:
  model_name: "Qwen/Qwen3-8B"
  max_new_tokens: 64
  temperature: 0.7

model_17:
  model_name: "Qwen/Qwen3-30B-A3B-Instruct-2507"
  max_new_tokens: 64
  temperature: 0.7

model_18:
  model_name: "Qwen/Qwen3-Next-80B-A3B-Instruct"
  max_new_tokens: 64
  temperature: 0.7

model_19:
  model_name: "HuggingFaceH4/zephyr-7b-beta"
  max_new_tokens: 64
  temperature: 0.7

model_20:
  model_name: "HuggingFaceTB/SmolLM3-3B"
  max_new_tokens: 64
  temperature: 0.7

model_21:
  model_name: "deepseek-ai/DeepSeek-R1"
  max_new_tokens: 64
  temperature: 0.7

model_22:
  model_name: "deepseek-ai/DeepSeek-V3"
  max_new_tokens: 64
  temperature: 0.7

model_23:
  model_name: "deepseek-ai/DeepSeek-R1-Distill-Qwen-7B"
  max_new_tokens: 64
  temperature: 0.7

model_24:
  model_name: "deepseek-ai/DeepSeek-R1-Distill-Qwen-14B"
  max_new_tokens: 64
  temperature: 0.7

model_25:
  model_name: "deepseek-ai/DeepSeek-R1-Distill-Llama-70B"
  max_new_tokens: 64
  temperature: 0.7

model_26:
  model_name: "deepseek-ai/DeepSeek-R1-0324"
  max_new_tokens: 64
  temperature: 0.7
